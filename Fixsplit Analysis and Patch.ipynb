{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from IPython.display import display\n",
    "\n",
    "from dvidutils import LabelMapper\n",
    "from DVIDSparkServices.util import Timer\n",
    "from DVIDSparkServices.io_util.labelmap_utils import mapping_from_edges\n",
    "from DVIDSparkServices.graph_comparison import (load_and_normalize_merge_table, normalize_merge_table,\n",
    "                                                load_supervoxel_sizes, \n",
    "                                                compute_comparison_mapping_table, compute_component_table,\n",
    "                                                compute_split_merge_stats, frequencies_by_size_thresholds,\n",
    "                                                extract_edges, MERGE_TABLE_DTYPE)\n",
    "\n",
    "# No need to add a handler -- root logger already has a handler via DVIDSparkServices.__init__\n",
    "#handler = logging.StreamHandler(sys.stdout)\n",
    "#logger.addHandler(handler)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nrs/flyem/bergs/final-agglo-fixsplit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "print('')\n",
    "#!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load merge graph tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_merge_table_path = '../final-agglo/final_20180312_32nm_16nm_all_cbs32_upto10_cb16_upto10_freeze_all.npy'\n",
    "old_merge_table = load_and_normalize_merge_table(old_merge_table_path)\n",
    "old_merge_table_df = pd.DataFrame(old_merge_table)\n",
    "old_edges = extract_edges(old_merge_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_merge_table_path = 'final_20180312_32nm_16nm_all_cbs32_upto10_cb16_upto10_freeze_all_upd0408_v2.npy'\n",
    "new_merge_table = load_and_normalize_merge_table(new_merge_table_path)\n",
    "new_merge_table_df = pd.DataFrame(new_merge_table)\n",
    "new_edges = extract_edges(new_merge_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervoxel sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO [2018-05-01 17:05:48,861] Volume contains 188243164 supervoxels and 22.5 Teravoxels in total\n"
     ]
    }
   ],
   "source": [
    "sizes_file = '/groups/flyem/data/scratchspace/copyseg-configs/labelmaps/hemibrain/8nm/compute-8nm-extended-fixed-STATS-ONLY-20180402.192015/supervoxel-sizes.h5'\n",
    "sv_sizes = load_supervoxel_sizes(sizes_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison mapping tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO [2018-04-23 13:18:28,760] Removing duplicate edges...\n",
      "INFO [2018-04-23 13:19:15,078] Removing duplicate edges took 0:00:46.317220\n",
      "INFO [2018-04-23 13:19:15,079] Computing intersection...\n",
      "INFO [2018-04-23 13:19:52,861] Computing intersection took 0:00:37.781029\n",
      "INFO [2018-04-23 13:19:52,863] Ensuring identical SV sets...\n",
      "INFO [2018-04-23 13:21:57,102] Ensuring identical SV sets took 0:02:04.238134\n",
      "INFO [2018-04-23 13:21:57,104] Computing old mapping...\n",
      "INFO [2018-04-23 13:24:07,360] Computing old mapping took 0:02:10.254389\n",
      "INFO [2018-04-23 13:24:07,364] Computing new mapping...\n",
      "INFO [2018-04-23 13:26:15,488] Computing new mapping took 0:02:08.121306\n",
      "INFO [2018-04-23 13:26:15,500] Computing intersection mapping...\n",
      "INFO [2018-04-23 13:28:42,355] Computing intersection mapping took 0:02:26.843481\n",
      "INFO [2018-04-23 13:28:43,644] Appending supervoxel sizes...\n",
      "INFO [2018-04-23 13:28:54,008] Appending supervoxel sizes took 0:00:10.361507\n"
     ]
    }
   ],
   "source": [
    "sv_table = compute_comparison_mapping_table(old_edges, new_edges, sv_sizes)\n",
    "component_table = compute_component_table(sv_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split/Merge stats (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "affected_components, split_body_stats, merge_body_stats = compute_split_merge_stats(component_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split frequencies (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size range</th>\n",
       "      <th>body count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;= 1 Gv</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100 Mv - 1 Gv</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Mv - 100 Mv</td>\n",
       "      <td>3494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Mv - 10 Mv</td>\n",
       "      <td>4290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100 kv - 1 Mv</td>\n",
       "      <td>3747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 kv - 100 kv</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt; 10 kv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>12438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size range  body count\n",
       "0         >= 1 Gv          14\n",
       "1   100 Mv - 1 Gv         497\n",
       "2  10 Mv - 100 Mv        3494\n",
       "3    1 Mv - 10 Mv        4290\n",
       "4   100 kv - 1 Mv        3747\n",
       "5  10 kv - 100 kv         396\n",
       "6         < 10 kv           0\n",
       "7           TOTAL       12438"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_by_size_thresholds(split_body_stats['remaining_voxels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge frequencies (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size range</th>\n",
       "      <th>body count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;= 1 Gv</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100 Mv - 1 Gv</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Mv - 100 Mv</td>\n",
       "      <td>5396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Mv - 10 Mv</td>\n",
       "      <td>15073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100 kv - 1 Mv</td>\n",
       "      <td>24662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 kv - 100 kv</td>\n",
       "      <td>2842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt; 10 kv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>48724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size range  body count\n",
       "0         >= 1 Gv          35\n",
       "1   100 Mv - 1 Gv         716\n",
       "2  10 Mv - 100 Mv        5396\n",
       "3    1 Mv - 10 Mv       15073\n",
       "4   100 kv - 1 Mv       24662\n",
       "5  10 kv - 100 kv        2842\n",
       "6         < 10 kv           0\n",
       "7           TOTAL       48724"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_by_size_thresholds(merge_body_stats['remaining_voxels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split/Merge stats (reviewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load reviewed bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'hemibrain_all_proofreader_bodies_041818.csv'\n",
    "reviewed_bodies = pd.read_csv(path, header=None, names=['body', 'reviewer', 'assignment'])['body']\n",
    "reviewed_bodies = set(map(np.uint64, reviewed_bodies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewed bodies are in the 'old' ID space, so computing the set of affected splits is easy\n",
    "reviewed_split_bodies = set(split_body_stats.query('old_body in @reviewed_bodies').index)\n",
    "\n",
    "q = '(old_body in @reviewed_split_bodies)'\n",
    "components_affected_by_reviewed_splits = affected_components.query(q)\n",
    "\n",
    "_affected_components, reviewed_split_body_stats, _ = \\\n",
    "    compute_split_merge_stats(components_affected_by_reviewed_splits)\n",
    "\n",
    "# If we selected the component rows correctly, every one of them should have been used.\n",
    "assert (_affected_components.values == components_affected_by_reviewed_splits.values).all()\n",
    "\n",
    "\n",
    "# Computing the set of merges that involve reviewed bodies\n",
    "# requires searching for bodies that include reviewed components.\n",
    "merged_bodies_with_reviewed_components = set()\n",
    "merged_components = affected_components.query('new_body in @merge_body_stats.index')\n",
    "for new_body, body_components in merged_components.groupby('new_body'):\n",
    "    if reviewed_bodies.intersection(body_components['old_body']):\n",
    "        merged_bodies_with_reviewed_components.add(new_body)\n",
    "\n",
    "q = '(new_body in @merged_bodies_with_reviewed_components)'\n",
    "components_affected_by_reviewed_merges = affected_components.query(q)\n",
    "\n",
    "_affected_components, _, reviewed_merge_body_stats = \\\n",
    "    compute_split_merge_stats(components_affected_by_reviewed_merges)\n",
    "\n",
    "# If we selected the component rows correctly, every one of them should have been used.\n",
    "assert (_affected_components.values == components_affected_by_reviewed_merges.values).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19494 bodies were affected\n"
     ]
    }
   ],
   "source": [
    "affected_new_bodies = np.concatenate((components_affected_by_reviewed_splits['new_body'].values, \n",
    "                                      components_affected_by_reviewed_merges['new_body'].values))\n",
    "affected_reviewed_bodies = pd.unique(affected_new_bodies.flat)\n",
    "print(f\"{len(affected_reviewed_bodies)} bodies were affected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19323"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_bodies_with_reviewed_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split frequencies (reviewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size range</th>\n",
       "      <th>body count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;= 1 Gv</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100 Mv - 1 Gv</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Mv - 100 Mv</td>\n",
       "      <td>2654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Mv - 10 Mv</td>\n",
       "      <td>2905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100 kv - 1 Mv</td>\n",
       "      <td>2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 kv - 100 kv</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt; 10 kv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>8372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size range  body count\n",
       "0         >= 1 Gv          13\n",
       "1   100 Mv - 1 Gv         339\n",
       "2  10 Mv - 100 Mv        2654\n",
       "3    1 Mv - 10 Mv        2905\n",
       "4   100 kv - 1 Mv        2250\n",
       "5  10 kv - 100 kv         211\n",
       "6         < 10 kv           0\n",
       "7           TOTAL        8372"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_by_size_thresholds(reviewed_split_body_stats['remaining_voxels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge frequencies (reviewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size range</th>\n",
       "      <th>body count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;= 1 Gv</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100 Mv - 1 Gv</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Mv - 100 Mv</td>\n",
       "      <td>3718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Mv - 10 Mv</td>\n",
       "      <td>6626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100 kv - 1 Mv</td>\n",
       "      <td>7418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 kv - 100 kv</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt; 10 kv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>19323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size range  body count\n",
       "0         >= 1 Gv          33\n",
       "1   100 Mv - 1 Gv         615\n",
       "2  10 Mv - 100 Mv        3718\n",
       "3    1 Mv - 10 Mv        6626\n",
       "4   100 kv - 1 Mv        7418\n",
       "5  10 kv - 100 kv         913\n",
       "6         < 10 kv           0\n",
       "7           TOTAL       19323"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_by_size_thresholds(reviewed_merge_body_stats['remaining_voxels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split/merge stats (UN-reviewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewed bodies are in the 'old' ID space, so computing the set of unaffected splits is easy\n",
    "unreviewed_split_bodies = set(split_body_stats.query('old_body not in @reviewed_bodies').index)\n",
    "\n",
    "q = '(old_body in @unreviewed_split_bodies)'\n",
    "components_affected_by_unreviewed_splits = affected_components.query(q)\n",
    "\n",
    "_affected_components, unreviewed_split_body_stats, _ = \\\n",
    "    compute_split_merge_stats(components_affected_by_unreviewed_splits)\n",
    "\n",
    "# If we selected the component rows correctly, every one of them should have been used.\n",
    "assert (_affected_components.values == components_affected_by_unreviewed_splits.values).all()\n",
    "\n",
    "\n",
    "# Computing the set of merges that involve unreviewed bodies\n",
    "# requires searching for bodies that include reviewed components (and taking those that don't).\n",
    "merged_bodies_with_unreviewed_components = set()\n",
    "old_bodies_affected_by_merges_of_unreviewed = set()\n",
    "merged_components = affected_components.query('new_body in @merge_body_stats.index')\n",
    "for new_body, body_components in merged_components.groupby('new_body'):\n",
    "    if not reviewed_bodies.intersection(body_components['old_body']):\n",
    "        old_bodies_affected_by_merges_of_unreviewed = \\\n",
    "            old_bodies_affected_by_merges_of_unreviewed.union(body_components['old_body'].values)\n",
    "        merged_bodies_with_unreviewed_components.add(new_body)\n",
    "\n",
    "q = '(new_body in @merged_bodies_with_unreviewed_components)'\n",
    "components_affected_by_unreviewed_merges = affected_components.query(q)\n",
    "\n",
    "_affected_components, _, unreviewed_merge_body_stats = \\\n",
    "    compute_split_merge_stats(components_affected_by_unreviewed_merges)\n",
    "\n",
    "# If we selected the component rows correctly, every one of them should have been used.\n",
    "assert (_affected_components.values == components_affected_by_unreviewed_merges.values).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split frequencies (UN-reviewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size range</th>\n",
       "      <th>body count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;= 1 Gv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100 Mv - 1 Gv</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Mv - 100 Mv</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Mv - 10 Mv</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100 kv - 1 Mv</td>\n",
       "      <td>1497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 kv - 100 kv</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt; 10 kv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>4066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size range  body count\n",
       "0         >= 1 Gv           1\n",
       "1   100 Mv - 1 Gv         158\n",
       "2  10 Mv - 100 Mv         840\n",
       "3    1 Mv - 10 Mv        1385\n",
       "4   100 kv - 1 Mv        1497\n",
       "5  10 kv - 100 kv         185\n",
       "6         < 10 kv           0\n",
       "7           TOTAL        4066"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_by_size_thresholds(unreviewed_split_body_stats['remaining_voxels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge frequencies (UN-reviewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size range</th>\n",
       "      <th>body count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&gt;= 1 Gv</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100 Mv - 1 Gv</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Mv - 100 Mv</td>\n",
       "      <td>1678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 Mv - 10 Mv</td>\n",
       "      <td>8447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100 kv - 1 Mv</td>\n",
       "      <td>17244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 kv - 100 kv</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt; 10 kv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TOTAL</td>\n",
       "      <td>29401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       size range  body count\n",
       "0         >= 1 Gv           2\n",
       "1   100 Mv - 1 Gv         101\n",
       "2  10 Mv - 100 Mv        1678\n",
       "3    1 Mv - 10 Mv        8447\n",
       "4   100 kv - 1 Mv       17244\n",
       "5  10 kv - 100 kv        1929\n",
       "6         < 10 kv           0\n",
       "7           TOTAL       29401"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies_by_size_thresholds(unreviewed_merge_body_stats['remaining_voxels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine graphs (accepted edges from each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll disallow merges or splits to any old bodies that were\n",
    "# reviewed OR that end up in the same merged component as any reviewed body.\n",
    "frozen_bodies = set(affected_components.query('new_body in @merged_bodies_with_reviewed_components')['old_body'])\n",
    "frozen_bodies = set(map(np.uint64, frozen_bodies.union(reviewed_bodies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178064"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frozen_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize filtered_new_merge_table_df as a copy of new_merge_table_df,\n",
    "# with appended columns: ['old_body_a', 'new_body_a', 'old_body_b', 'new_body_b']\n",
    "filtered_new_merge_table_df = new_merge_table_df.merge(sv_table[['old_body', 'new_body']],\n",
    "                                                       left_on='id_a', right_index=True, copy=False)\n",
    "\n",
    "filtered_new_merge_table_df = filtered_new_merge_table_df.merge(sv_table[['old_body', 'new_body']],\n",
    "                                                                left_on='id_b', right_index=True, copy=False,\n",
    "                                                                suffixes=('_a', '_b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept all new edges EXCEPT merging old bodies and either body is supposed to be frozen\n",
    "q = '(old_body_a == old_body_b) or ((old_body_a not in @frozen_bodies) and (old_body_b not in @frozen_bodies))'\n",
    "filtered_new_merge_table_df = filtered_new_merge_table_df.query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize filtered_old_merge_table_df as a copy of old_merge_table_df,\n",
    "# with appended columns: ['old_body_a', 'new_body_a', 'old_body_b', 'new_body_b']\n",
    "filtered_old_merge_table_df = old_merge_table_df.merge(sv_table[['old_body', 'new_body']],\n",
    "                                                       left_on='id_a', right_index=True, copy=False)\n",
    "\n",
    "filtered_old_merge_table_df = filtered_old_merge_table_df.merge(sv_table[['old_body', 'new_body']],\n",
    "                                                                left_on='id_b', right_index=True, copy=False,\n",
    "                                                                suffixes=('_a', '_b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reject all old edges EXCEPT merges between frozen bodies that are missing in the new agglo.\n",
    "#q = '(old_body_a in @frozen_bodies) and (new_body_a != new_body_b)'\n",
    "\n",
    "# Actually, accept all edges involving any frozen bodies.\n",
    "# This will result in some dupes, which we're dropping anyway, next\n",
    "q = '(old_body_a in @frozen_bodies)'\n",
    "filtered_old_merge_table_df = filtered_old_merge_table_df.query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original merge tables included duplicates, so there might be duplicates in the filtered versions.\n",
    "old_dupe_rows = filtered_old_merge_table_df[['id_a', 'id_b']].duplicated(keep='last')\n",
    "filtered_old_merge_table_df = filtered_old_merge_table_df[~old_dupe_rows]\n",
    "\n",
    "new_dupe_rows = filtered_new_merge_table_df[['id_a', 'id_b']].duplicated(keep='last')\n",
    "filtered_new_merge_table_df = filtered_new_merge_table_df[~new_dupe_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 9091541 duplicate edges between the old and new agglos\n"
     ]
    }
   ],
   "source": [
    "# Combine\n",
    "combined_merge_table_df = pd.concat((filtered_old_merge_table_df, filtered_new_merge_table_df))\n",
    "\n",
    "# De-dupe\n",
    "dupe_rows = combined_merge_table_df.duplicated(['id_a', 'id_b'], 'last')\n",
    "print(f\"There were {dupe_rows.sum()} duplicate edges between the old and new agglos\")\n",
    "\n",
    "## Sanity check -- we didn't carry over any edges from 'old' that were already present in 'new'\n",
    "## EDIT: Not true any more -- I changed the old table filter.\n",
    "#assert dupe_rows.sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9143050, 13), (32523315, 13), (41666365, 13))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_old_merge_table_df.shape, filtered_new_merge_table_df.shape, combined_merge_table_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(filtered_old_merge_table_df.query('id_a == 851377905 or id_b == 851377905'))\n",
    "#display(filtered_new_merge_table_df.query('id_a == 851377905 or id_b == 851377905'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "merge_table_columns = [name for (name, dtype) in MERGE_TABLE_DTYPE]\n",
    "combined_merge_table = combined_merge_table_df[merge_table_columns].to_records(index=False)\n",
    "assert combined_merge_table.dtype == MERGE_TABLE_DTYPE\n",
    "np.save('combined_merge_table.npy', combined_merge_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32249777,), (32716517,), (41666365,))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_merge_table.shape, new_merge_table.shape, combined_merge_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85184,)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(filtered_old_merge_table_df[['old_body_a', 'old_body_b']].values.flat).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks -- We should not see any changes to reviewed bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO [2018-04-25 18:39:21,215] Removing duplicate edges...\n",
      "INFO [2018-04-25 18:40:12,593] Removing duplicate edges took 0:00:51.376863\n",
      "INFO [2018-04-25 18:40:12,595] Computing intersection...\n",
      "INFO [2018-04-25 18:40:45,891] Computing intersection took 0:00:33.295257\n",
      "INFO [2018-04-25 18:40:45,892] Ensuring identical SV sets...\n",
      "INFO [2018-04-25 18:42:45,239] Ensuring identical SV sets took 0:01:59.346559\n",
      "INFO [2018-04-25 18:42:45,241] Computing old mapping...\n",
      "INFO [2018-04-25 18:44:36,892] Computing old mapping took 0:01:51.650759\n",
      "INFO [2018-04-25 18:44:36,894] Computing new mapping...\n",
      "INFO [2018-04-25 18:46:19,113] Computing new mapping took 0:01:42.218216\n",
      "INFO [2018-04-25 18:46:19,115] Computing intersection mapping...\n",
      "INFO [2018-04-25 18:47:51,841] Computing intersection mapping took 0:01:32.724847\n",
      "INFO [2018-04-25 18:47:53,178] Appending supervoxel sizes...\n",
      "INFO [2018-04-25 18:48:03,216] Appending supervoxel sizes took 0:00:10.037088\n"
     ]
    }
   ],
   "source": [
    "combined_edges = extract_edges(combined_merge_table)\n",
    "combined_sv_table = compute_comparison_mapping_table(old_edges, combined_edges, sv_sizes)\n",
    "combined_component_table = compute_component_table(combined_sv_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2996, 4), (29513, 4))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_affected_components, combined_split_body_stats, combined_merge_body_stats = \\\n",
    "    compute_split_merge_stats(combined_component_table)\n",
    "\n",
    "combined_split_body_stats.shape, combined_merge_body_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewed bodies are in the 'old' ID space, so computing the set of affected splits is easy\n",
    "combined_reviewed_split_bodies = set(combined_split_body_stats.query('old_body in @reviewed_bodies').index)\n",
    "\n",
    "q = '(old_body in @reviewed_split_bodies)'\n",
    "combined_components_affected_by_reviewed_splits = combined_affected_components.query(q)\n",
    "\n",
    "_affected_components, combined_reviewed_split_body_stats, _ = \\\n",
    "    compute_split_merge_stats(combined_components_affected_by_reviewed_splits)\n",
    "\n",
    "# If we selected the component rows correctly, every one of them should have been used.\n",
    "assert (_affected_components.values == combined_components_affected_by_reviewed_splits.values).all()\n",
    "\n",
    "\n",
    "# Computing the set of merges that involve reviewed bodies\n",
    "# requires searching for bodies that include reviewed components.\n",
    "combined_merged_bodies_with_reviewed_components = set()\n",
    "combined_merged_components = combined_affected_components.query('new_body in @combined_merge_body_stats.index')\n",
    "for new_body, body_components in combined_merged_components.groupby('new_body'):\n",
    "    if reviewed_bodies.intersection(body_components['old_body']):\n",
    "        combined_merged_bodies_with_reviewed_components.add(new_body)\n",
    "\n",
    "q = '(new_body in @combined_merged_bodies_with_reviewed_components)'\n",
    "combined_components_affected_by_reviewed_merges = combined_affected_components.query(q)\n",
    "\n",
    "_affected_components, _, combined_reviewed_merge_body_stats = \\\n",
    "    compute_split_merge_stats(combined_components_affected_by_reviewed_merges)\n",
    "\n",
    "# If we selected the component rows correctly, every one of them should have been used.\n",
    "assert (_affected_components.values == combined_components_affected_by_reviewed_merges.values).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_merged_bodies_with_reviewed_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_reviewed_split_bodies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename phantoms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load phantom lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantoms = set(pd.read_csv('phantoms.csv', header=None, names=['sv'])['sv'])\n",
    "large_renames = pd.read_csv('manual-phantom-renames.csv')\n",
    "large_phantoms = set(large_renames['old'])\n",
    "assert len(large_phantoms - phantoms) == 0\n",
    "small_phantoms = phantoms - large_phantoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "patched_merge_table = combined_merge_table.copy()\n",
    "patched_merge_table_df = pd.DataFrame(patched_merge_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_phantom_rows_view = combined_merge_table_df.query('id_a in @small_phantoms or id_b in @small_phantoms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose renames for 'small' phantoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882cbb35535340269c1f9433242da7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=306), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There were 7 phantoms that were not attached to any non-phantoms:\n",
      "[1391938980, 1391938982, 2491461668, 2491461671, 2491461672, 608935042, 608935044]\n"
     ]
    }
   ],
   "source": [
    "# Choose renames for small phantoms\n",
    "small_phantom_rows = small_phantom_rows_view.copy()\n",
    "small_renames = []\n",
    "\n",
    "iter_count = 0\n",
    "small_phantom_to_process = list(small_phantoms)\n",
    "with tqdm_notebook(total=len(small_phantom_to_process)) as progress:\n",
    "    while small_phantom_to_process and iter_count < 500:\n",
    "        iter_count += 1\n",
    "        phantom = small_phantom_to_process.pop(0)\n",
    "        row_loc = (small_phantom_rows['id_a'] == phantom) | (small_phantom_rows['id_b'] == phantom)\n",
    "        rows = small_phantom_rows[row_loc]\n",
    "        rows = rows.sort_values('score')\n",
    "\n",
    "        # Find the first connection that isn't also a phantom\n",
    "        other = None\n",
    "        for row in list(rows.itertuples()):\n",
    "            if row.id_a not in small_phantoms:\n",
    "                other = row.id_a\n",
    "                break\n",
    "            elif row.id_b not in small_phantoms:\n",
    "                other = row.id_b\n",
    "                break\n",
    "\n",
    "        if other is None:\n",
    "            small_phantom_to_process.append(phantom)\n",
    "            #print(f\"Moving phantom {phantom} to the end of the list (N={len(small_phantom_to_process)}).\")\n",
    "            continue\n",
    "\n",
    "        small_renames.append((phantom, other))\n",
    "\n",
    "        # Replace in the small_phantoms, so it becomes an option for neighboring phantoms.\n",
    "        small_phantom_rows.iloc[(small_phantom_rows['id_a'] == phantom).values, 0] = other\n",
    "        small_phantom_rows.iloc[(small_phantom_rows['id_b'] == phantom).values, 1] = other\n",
    "\n",
    "        progress.update(1)\n",
    "\n",
    "# Any IDs left at this point were not connected to any 'real' SVs\n",
    "# Just map them to zero, and we'll discard them later.\n",
    "print(f\"There were {len(small_phantom_to_process)} phantoms that were not attached to any non-phantoms:\")\n",
    "print(small_phantom_to_process)\n",
    "for phantom in small_phantom_to_process:\n",
    "    small_renames.append((phantom, 0))\n",
    "\n",
    "small_renames = pd.DataFrame(small_renames, columns=['old', 'new'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply renames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_renames.to_csv('small-phantom-rename-table.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_renames = pd.concat((large_renames, small_renames))\n",
    "assert all_renames.shape == (330, 2)\n",
    "\n",
    "renames_old = set(all_renames['old'])\n",
    "renames_new = set(all_renames['new'])\n",
    "\n",
    "# Select rows to patch\n",
    "patch_loc = (  patched_merge_table_df['id_a'].isin(renames_old)\n",
    "             | patched_merge_table_df['id_b'].isin(renames_old) )\n",
    "\n",
    "patch_rows = patched_merge_table_df[patch_loc].copy()\n",
    "\n",
    "# Map old->new\n",
    "patches_a = patch_rows[['id_a']].merge(all_renames, how='left', left_on=['id_a'], right_on=['old'])\n",
    "patches_b = patch_rows[['id_b']].merge(all_renames, how='left', left_on=['id_b'], right_on=['old'])\n",
    "\n",
    "patches_a.index = patch_rows.index\n",
    "patches_b.index = patch_rows.index\n",
    "\n",
    "patches_a['new'] = patches_a['new'].fillna(patch_rows['id_a'])\n",
    "patches_b['new'] = patches_b['new'].fillna(patch_rows['id_b'])\n",
    "\n",
    "patch_rows['id_a'] = patches_a['new'].astype(np.uint64)\n",
    "patch_rows['id_b'] = patches_b['new'].astype(np.uint64)\n",
    "\n",
    "patched_merge_table_df[patch_loc] = patch_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "patched_merge_table_df = patched_merge_table_df.query('id_a != 0 and id_b != 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did we eliminate all phantoms?\n",
    "assert patched_merge_table_df['id_a'].isin(phantoms).sum() == 0\n",
    "assert patched_merge_table_df['id_b'].isin(phantoms).sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "patched_merge_table = patched_merge_table_df[merge_table_columns].to_records(index=False)\n",
    "patched_merge_table = patched_merge_table.view(MERGE_TABLE_DTYPE)\n",
    "patched_merge_table = normalize_merge_table(patched_merge_table)\n",
    "patched_merge_table_df = pd.DataFrame(patched_merge_table)\n",
    "\n",
    "# Save\n",
    "np.save('patched_combined_merge_table.npy', patched_merge_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit merges (to fix errors after splits were applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuity_fixes_edges = pd.read_csv('aux_merges_split_bodies_continuity.csv', header=None, names=['id_a', 'id_b'], dtype=np.uint64)\n",
    "continuity_fixes_edges = np.sort(continuity_fixes_edges.values, axis=1)\n",
    "\n",
    "continuity_fixes_merge_table = np.zeros((len(continuity_fixes_edges,)), dtype=MERGE_TABLE_DTYPE)\n",
    "continuity_fixes_merge_table['id_a'] = continuity_fixes_edges[:,0]\n",
    "continuity_fixes_merge_table['id_b'] = continuity_fixes_edges[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge_table = np.concatenate((patched_merge_table, continuity_fixes_merge_table))\n",
    "np.save('final_merge_table.npy', final_merge_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../final-agglo-fixsplit-patched/final_patched_20180426_merge_table.npy', final_merge_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload from disk (for starting from fresh kernel)\n",
    "final_merge_table = np.load('../final-agglo-fixsplit-patched/final_patched_20180426_merge_table.npy')\n",
    "final_edges = extract_edges(final_merge_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32575002,)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO [2018-05-02 17:14:02,220] Removing duplicate edges...\n",
      "INFO [2018-05-02 17:14:52,119] Removing duplicate edges took 0:00:49.897857\n",
      "INFO [2018-05-02 17:14:52,121] Computing intersection...\n",
      "INFO [2018-05-02 17:15:27,680] Computing intersection took 0:00:35.558661\n",
      "INFO [2018-05-02 17:15:27,682] Ensuring identical SV sets...\n",
      "INFO [2018-05-02 17:19:39,852] Computing old mapping took 0:02:01.728812\n",
      "INFO [2018-05-02 17:19:39,854] Computing new mapping...\n",
      "INFO [2018-05-02 17:21:19,389] Computing new mapping took 0:01:39.534640\n",
      "INFO [2018-05-02 17:21:19,391] Computing intersection mapping...\n",
      "INFO [2018-05-02 17:22:55,626] Computing intersection mapping took 0:01:36.234430\n",
      "INFO [2018-05-02 17:22:56,970] Appending supervoxel sizes...\n",
      "INFO [2018-05-02 17:23:06,884] Appending supervoxel sizes took 0:00:09.913777\n"
     ]
    }
   ],
   "source": [
    "final_sv_table = compute_comparison_mapping_table(old_edges, final_edges, sv_sizes)\n",
    "final_component_table = compute_component_table(final_sv_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_affected_components, final_split_body_stats, final_merge_body_stats = \\\n",
    "    compute_split_merge_stats(final_component_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewed bodies are in the 'old' ID space, so computing the set of affected splits is easy\n",
    "final_reviewed_split_bodies = set(final_split_body_stats.query('old_body in @reviewed_bodies').index)\n",
    "\n",
    "q = '(old_body in @final_reviewed_split_bodies)'\n",
    "final_components_affected_by_reviewed_splits = final_affected_components.query(q)\n",
    "\n",
    "_affected_components, final_reviewed_split_body_stats, _ = \\\n",
    "    compute_split_merge_stats(final_components_affected_by_reviewed_splits)\n",
    "\n",
    "# If we selected the component rows correctly, every one of them should have been used.\n",
    "assert (_affected_components.values == final_components_affected_by_reviewed_splits.values).all()\n",
    "\n",
    "\n",
    "# Computing the set of merges that involve reviewed bodies\n",
    "# requires searching for bodies that include reviewed components.\n",
    "final_merged_bodies_with_reviewed_components = set()\n",
    "final_merged_components = final_affected_components.query('new_body in @final_merge_body_stats.index')\n",
    "for new_body, body_components in final_merged_components.groupby('new_body'):\n",
    "    if reviewed_bodies.intersection(body_components['old_body']):\n",
    "        final_merged_bodies_with_reviewed_components.add(new_body)\n",
    "\n",
    "q = '(new_body in @final_merged_bodies_with_reviewed_components)'\n",
    "final_components_affected_by_reviewed_merges = final_affected_components.query(q)\n",
    "\n",
    "_affected_components, _, final_reviewed_merge_body_stats = \\\n",
    "    compute_split_merge_stats(final_components_affected_by_reviewed_merges)\n",
    "\n",
    "# If we selected the component rows correctly, every one of them should have been used.\n",
    "assert (_affected_components.values == final_components_affected_by_reviewed_merges.values).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_old_bodies_in_merges = pd.unique(final_components_affected_by_reviewed_merges['old_body'])\n",
    "len(final_old_bodies_in_merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_reviewed_split_bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(final_old_bodies_in_merges).to_csv('old-reviewed-bodies-in-new-merges.csv', index=False, header=False)\n",
    "final_components_affected_by_reviewed_merges['new_body'].drop_duplicates()\\\n",
    "    .to_csv('new-merged-bodies-to-review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nrs/flyem/bergs/final-agglo-fixsplit/old-reviewed-bodies-in-new-merges.csv\n",
      "/nrs/flyem/bergs/final-agglo-fixsplit/new-merged-bodies-to-review.csv\n"
     ]
    }
   ],
   "source": [
    "!ls $(pwd)/old-reviewed-bodies-in-new-merges.csv\n",
    "!ls $(pwd)/new-merged-bodies-to-review.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((222,), (81,))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_old_bodies_in_merges.shape, final_components_affected_by_reviewed_merges['new_body'].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(661403761 in final_old_bodies_in_merges,\n",
    "661403761 in final_components_affected_by_reviewed_merges['new_body'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There should be no real 'splits' on old bodies EXCEPT for bodies involving phantoms.\n",
    "# (The 'phantom' was removed from the final agglo, so it appears 'split' from the body.)\n",
    "final_split_sv_table = final_sv_table.query('old_body in @final_reviewed_split_bodies')\n",
    "\n",
    "d = {}\n",
    "for old_body, table in final_split_sv_table.groupby('old_body'):\n",
    "    d[old_body] = len(set(table.index).intersection(phantoms))\n",
    "\n",
    "assert all(d.values()), \"An old body was split despite containing no phantoms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 26.4 s, total: 1min 53s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%time final_mapping = mapping_from_edges(final_edges, as_series=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_components_affected_by_reviewed_merges['new_body'].to_csv('new-merged-bodies-to-review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247, 1)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!head new-merged-bodies-to-review.csv\n",
    "mnbtr = pd.read_csv('new-merged-bodies-to-review.csv', header=None, names=['body'])\n",
    "mnbtr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41037730"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41132595"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sv_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3279, 29669)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_split_body_stats), len(final_merge_body_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_merge_body_stats = final_merge_body_stats.query('body_voxels > 10e6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2969, 4)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_split_body_stats = final_split_body_stats.query('body_voxels > 10e6')\n",
    "large_split_body_stats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9655243, 1)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_mapping).query('sv == body').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mapping_no_identities = pd.DataFrame(final_mapping).query('sv != body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'final_patched_20180426_mapping_no_identities.csv'\n",
    "final_mapping_no_identities.to_csv(f'../final-agglo-fixsplit-patched/{name}', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'final_patched_20180426_mapping.csv'\n",
    "final_mapping.to_csv(f'../final-agglo-fixsplit-patched/{name}', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewed_svs = sv_table.query('old_body in @reviewed_bodies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewed_merge_table_df = old_merge_table_df.query('id_a in @reviewed_svs.index or id_b in @reviewed_svs.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = final_merge_table_mapped_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_a</th>\n",
       "      <th>id_b</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106979579</td>\n",
       "      <td>2386468249</td>\n",
       "      <td>5.117693</td>\n",
       "      <td>106979579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108002724</td>\n",
       "      <td>108343758</td>\n",
       "      <td>9.293223</td>\n",
       "      <td>108002724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108002724</td>\n",
       "      <td>108343809</td>\n",
       "      <td>12.983173</td>\n",
       "      <td>108002724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108002724</td>\n",
       "      <td>139378772</td>\n",
       "      <td>4.019378</td>\n",
       "      <td>108002724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108002724</td>\n",
       "      <td>139378775</td>\n",
       "      <td>9.128134</td>\n",
       "      <td>108002724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_a        id_b      score       body\n",
       "0  106979579  2386468249   5.117693  106979579\n",
       "1  108002724   108343758   9.293223  108002724\n",
       "2  108002724   108343809  12.983173  108002724\n",
       "3  108002724   139378772   4.019378  108002724\n",
       "4  108002724   139378775   9.128134  108002724"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.01 s, sys: 2.75 s, total: 3.76 s\n",
      "Wall time: 3.76 s\n"
     ]
    }
   ],
   "source": [
    "%time f2 = pd.concat((f, f[0:2]), ignore_index=True, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('/tmp/final.sqlite')\n",
    "c = conn.cursor()\n",
    "#c.execute('CREATE TABLE supervoxels (supervoxel_id INTEGER, agglo_id INTEGER)')\n",
    "#c.execute('CREATE INDEX supervoxels_by_supervoxel_id_index ON supervoxels (supervoxel_id)')\n",
    "#c.execute('CREATE INDEX supervoxels_by_agglo_id_index ON supervoxels (agglo_id)')\n",
    "#c.execute('CREATE TABLE edges (id_a INTEGER, id_b INTEGER, score REAL, body_id INTEGER)')\n",
    "#c.execute('CREATE INDEX edge_body_index ON edges (body_id)')\n",
    "\n",
    "f.to_sql('merge_table', )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_body_sizes['accumulated_voxels'] = np.add.accumulate(old_body_sizes['voxel_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_body_sizes['accumulated_percent'] = old_body_sizes['accumulated_voxels'] / neuron_total_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97565"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(old_body_sizes['accumulated_percent'] < 0.7).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voxel_count</th>\n",
       "      <th>segment_count</th>\n",
       "      <th>accumulated_voxels</th>\n",
       "      <th>accumulated_percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1498414905</th>\n",
       "      <td>6332043</td>\n",
       "      <td>4</td>\n",
       "      <td>15723386341095</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840872780</th>\n",
       "      <td>6331964</td>\n",
       "      <td>4</td>\n",
       "      <td>15723392673059</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694781425</th>\n",
       "      <td>6331949</td>\n",
       "      <td>6</td>\n",
       "      <td>15723399005008</td>\n",
       "      <td>0.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195308802</th>\n",
       "      <td>6331909</td>\n",
       "      <td>2</td>\n",
       "      <td>15723405336917</td>\n",
       "      <td>0.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018247616</th>\n",
       "      <td>6331909</td>\n",
       "      <td>4</td>\n",
       "      <td>15723411668826</td>\n",
       "      <td>0.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377132441</th>\n",
       "      <td>6331877</td>\n",
       "      <td>5</td>\n",
       "      <td>15723418000703</td>\n",
       "      <td>0.700002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089380989</th>\n",
       "      <td>6331866</td>\n",
       "      <td>8</td>\n",
       "      <td>15723424332569</td>\n",
       "      <td>0.700002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387179983</th>\n",
       "      <td>6331863</td>\n",
       "      <td>7</td>\n",
       "      <td>15723430664432</td>\n",
       "      <td>0.700002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752175862</th>\n",
       "      <td>6331829</td>\n",
       "      <td>2</td>\n",
       "      <td>15723436996261</td>\n",
       "      <td>0.700002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474090343</th>\n",
       "      <td>6331803</td>\n",
       "      <td>18</td>\n",
       "      <td>15723443328064</td>\n",
       "      <td>0.700003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            voxel_count  segment_count  accumulated_voxels  \\\n",
       "body                                                         \n",
       "1498414905      6332043              4      15723386341095   \n",
       "1840872780      6331964              4      15723392673059   \n",
       "1694781425      6331949              6      15723399005008   \n",
       "1195308802      6331909              2      15723405336917   \n",
       "1018247616      6331909              4      15723411668826   \n",
       "1377132441      6331877              5      15723418000703   \n",
       "2089380989      6331866              8      15723424332569   \n",
       "387179983       6331863              7      15723430664432   \n",
       "1752175862      6331829              2      15723436996261   \n",
       "2474090343      6331803             18      15723443328064   \n",
       "\n",
       "            accumulated_percent  \n",
       "body                             \n",
       "1498414905             0.700000  \n",
       "1840872780             0.700000  \n",
       "1694781425             0.700001  \n",
       "1195308802             0.700001  \n",
       "1018247616             0.700001  \n",
       "1377132441             0.700002  \n",
       "2089380989             0.700002  \n",
       "387179983              0.700002  \n",
       "1752175862             0.700002  \n",
       "2474090343             0.700003  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_body_sizes[248451:248461]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_body_sizes['accumulated_percent_of_bodies'] = old_body_sizes['accumulated_voxels'] / old_body_sizes['voxel_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56788"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(old_body_sizes['accumulated_percent_of_bodies'] < 0.7).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188243164,)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.461973722635999"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_sizes.sum() / 1e12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_classes = pd.read_csv('classifications.csv')\n",
    "sv_classes.columns = ['sv', 'class']\n",
    "sv_classes.set_index('sv', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_classes_with_size = pd.DataFrame(sv_sizes).merge(sv_classes, 'left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_classes_with_size.columns = ['voxel_count', 'klass']\n",
    "sv_classes_with_size.index = sv_classes_with_size.index.values.astype(np.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_classes = set([5,6])  # Without cell bodies\n",
    "#neuron_classes = set([3,5,6]) # With cell bodies\n",
    "neuron_sv_classes_with_size = sv_classes_with_size.query('klass in @neuron_classes')\n",
    "neuron_total_voxels = neuron_sv_classes_with_size['voxel_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "for size in [0, 1e5, 1e6, 1e7, 1e8]:\n",
    "    objects = neuron_sv_classes_with_size[neuron_sv_classes_with_size['voxel_count'] > size]\n",
    "    num_objects = objects.shape[0]\n",
    "    objects_total_voxels = objects['voxel_count'].sum()\n",
    "    fraction_of_volume = objects_total_voxels / neuron_total_voxels\n",
    "    table.append( (size, num_objects, objects_total_voxels, fraction_of_volume*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>num objects</th>\n",
       "      <th>total voxels</th>\n",
       "      <th>fraction of total voxels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>147925884</td>\n",
       "      <td>16454639639102</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>7351147</td>\n",
       "      <td>14657389844439</td>\n",
       "      <td>89.077550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2451815</td>\n",
       "      <td>13192847370777</td>\n",
       "      <td>80.177067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000000.0</td>\n",
       "      <td>165584</td>\n",
       "      <td>6787770183114</td>\n",
       "      <td>41.251406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000000.0</td>\n",
       "      <td>11585</td>\n",
       "      <td>3114323515944</td>\n",
       "      <td>18.926720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          size  num objects    total voxels  fraction of total voxels\n",
       "0          0.0    147925884  16454639639102                100.000000\n",
       "1     100000.0      7351147  14657389844439                 89.077550\n",
       "2    1000000.0      2451815  13192847370777                 80.177067\n",
       "3   10000000.0       165584   6787770183114                 41.251406\n",
       "4  100000000.0        11585   3114323515944                 18.926720"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(table, columns=['size', 'num objects', 'total voxels', 'fraction of total voxels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neuron_classes = set([5,6])  # Without cell bodies\n",
    "neuron_classes = set([3,5,6]) # With cell bodies\n",
    "neuron_sv_classes_with_size = sv_classes_with_size.query('klass in @neuron_classes')\n",
    "neuron_total_voxels = neuron_sv_classes_with_size['voxel_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "for size in [0, 1e5, 1e6, 1e7, 1e8]:\n",
    "    objects = neuron_sv_classes_with_size[neuron_sv_classes_with_size['voxel_count'] > size]\n",
    "    num_objects = objects.shape[0]\n",
    "    objects_total_voxels = objects['voxel_count'].sum()\n",
    "    fraction_of_volume = objects_total_voxels / neuron_total_voxels\n",
    "    table.append( (size, num_objects, objects_total_voxels, fraction_of_volume*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>num objects</th>\n",
       "      <th>total voxels</th>\n",
       "      <th>fraction of total voxels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>159903575</td>\n",
       "      <td>20029685679301</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>8330175</td>\n",
       "      <td>18133561147779</td>\n",
       "      <td>90.533428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>2688608</td>\n",
       "      <td>16439615151039</td>\n",
       "      <td>82.076251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000000.0</td>\n",
       "      <td>217074</td>\n",
       "      <td>9500789425405</td>\n",
       "      <td>47.433542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000000.0</td>\n",
       "      <td>16825</td>\n",
       "      <td>4176162089339</td>\n",
       "      <td>20.849863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          size  num objects    total voxels  fraction of total voxels\n",
       "0          0.0    159903575  20029685679301                100.000000\n",
       "1     100000.0      8330175  18133561147779                 90.533428\n",
       "2    1000000.0      2688608  16439615151039                 82.076251\n",
       "3   10000000.0       217074   9500789425405                 47.433542\n",
       "4  100000000.0        16825   4176162089339                 20.849863"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(table, columns=['size', 'num objects', 'total voxels', 'fraction of total voxels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sv_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_mapper = LabelMapper(old_mapping.index.values.astype(np.uint64), old_mapping.values[:, 0].astype(np.uint64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_classes_with_size['old_body'] = old_mapper.apply(sv_classes_with_size.index.values, allow_unmapped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>voxel_count</th>\n",
       "      <th>klass</th>\n",
       "      <th>old_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79355095</th>\n",
       "      <td>335838088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79355095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79359413</th>\n",
       "      <td>195016</td>\n",
       "      <td>7.0</td>\n",
       "      <td>79359413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79359414</th>\n",
       "      <td>9616</td>\n",
       "      <td>7.0</td>\n",
       "      <td>79359414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79696138</th>\n",
       "      <td>75229447</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79696138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79696139</th>\n",
       "      <td>480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79696139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79696140</th>\n",
       "      <td>339152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79696140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79696160</th>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79696160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79696161</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79696161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79700460</th>\n",
       "      <td>80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79700460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79700468</th>\n",
       "      <td>8984</td>\n",
       "      <td>7.0</td>\n",
       "      <td>79700468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          voxel_count  klass  old_body\n",
       "79355095    335838088    1.0  79355095\n",
       "79359413       195016    7.0  79359413\n",
       "79359414         9616    7.0  79359414\n",
       "79696138     75229447    1.0  79696138\n",
       "79696139          480    1.0  79696139\n",
       "79696140       339152    1.0  79696140\n",
       "79696160           80    1.0  79696160\n",
       "79696161            2    NaN  79696161\n",
       "79700460           80    1.0  79700460\n",
       "79700468         8984    7.0  79700468"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_classes_with_size[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_classes_with_sizes = sv_classes_with_size.groupby('old_body').agg({'klass': 'min', 'voxel_count': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neuron_classes = set([5,6])  # Without cell bodies\n",
    "neuron_classes = set([3,5,6]) # With cell bodies\n",
    "neuron_body_classes_with_size = body_classes_with_sizes.query('klass in @neuron_classes')\n",
    "neuron_total_voxels = neuron_body_classes_with_size['voxel_count'].sum()\n",
    "\n",
    "table = []\n",
    "for size in [0, 1e5, 1e6, 1e7, 1e8]:\n",
    "    objects = neuron_body_classes_with_size[neuron_body_classes_with_size['voxel_count'] > size]\n",
    "    num_objects = objects.shape[0]\n",
    "    objects_total_voxels = objects['voxel_count'].sum()\n",
    "    fraction_of_volume = objects_total_voxels / neuron_total_voxels\n",
    "    table.append( (size, num_objects, objects_total_voxels, fraction_of_volume*100) )\n",
    "\n",
    "pd.DataFrame(table, columns=['size', 'num objects', 'total voxels', 'fraction of total voxels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/flyem/proj/cluster/miniforge/envs/flyem/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "neuron_body_classes_with_size.sort_values('voxel_count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/flyem/proj/cluster/miniforge/envs/flyem/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "neuron_body_classes_with_size['accumulated_voxel_count'] = \\\n",
    "    np.add.accumulate(neuron_body_classes_with_size['voxel_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>klass</th>\n",
       "      <th>voxel_count</th>\n",
       "      <th>accumulated_voxel_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old_body</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541620506</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7356734.0</td>\n",
       "      <td>9.748614e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           klass  voxel_count  accumulated_voxel_count\n",
       "old_body                                              \n",
       "541620506    6.0    7356734.0             9.748614e+12"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_70pct = (neuron_body_classes_with_size['accumulated_voxel_count'] / neuron_body_classes_with_size['voxel_count'].sum() > 0.7).values.nonzero()[0][0]\n",
    "print(index_70pct)\n",
    "neuron_body_classes_with_size[index_70pct:index_70pct+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>num objects</th>\n",
       "      <th>total voxels</th>\n",
       "      <th>fraction of total voxels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>118085483</td>\n",
       "      <td>1.392659e+13</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>4696658</td>\n",
       "      <td>1.257657e+13</td>\n",
       "      <td>90.306132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>891795</td>\n",
       "      <td>1.163720e+13</td>\n",
       "      <td>83.561018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000000.0</td>\n",
       "      <td>144620</td>\n",
       "      <td>9.347256e+12</td>\n",
       "      <td>67.118047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000000.0</td>\n",
       "      <td>19889</td>\n",
       "      <td>6.077680e+12</td>\n",
       "      <td>43.640831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          size  num objects  total voxels  fraction of total voxels\n",
       "0          0.0    118085483  1.392659e+13                100.000000\n",
       "1     100000.0      4696658  1.257657e+13                 90.306132\n",
       "2    1000000.0       891795  1.163720e+13                 83.561018\n",
       "3   10000000.0       144620  9.347256e+12                 67.118047\n",
       "4  100000000.0        19889  6.077680e+12                 43.640831"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_classes = set([5,6])  # Without cell bodies\n",
    "#neuron_classes = set([3,5,6]) # With cell bodies\n",
    "neuron_body_classes_with_size = body_classes_with_sizes.query('klass in @neuron_classes')\n",
    "neuron_total_voxels = neuron_body_classes_with_size['voxel_count'].sum()\n",
    "\n",
    "table = []\n",
    "for size in [0, 1e5, 1e6, 1e7, 1e8]:\n",
    "    objects = neuron_body_classes_with_size[neuron_body_classes_with_size['voxel_count'] > size]\n",
    "    num_objects = objects.shape[0]\n",
    "    objects_total_voxels = objects['voxel_count'].sum()\n",
    "    fraction_of_volume = objects_total_voxels / neuron_total_voxels\n",
    "    table.append( (size, num_objects, objects_total_voxels, fraction_of_volume*100) )\n",
    "\n",
    "pd.DataFrame(table, columns=['size', 'num objects', 'total voxels', 'fraction of total voxels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/flyem/proj/cluster/miniforge/envs/flyem/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "neuron_body_classes_with_size.sort_values('voxel_count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/groups/flyem/proj/cluster/miniforge/envs/flyem/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>klass</th>\n",
       "      <th>voxel_count</th>\n",
       "      <th>accumulated_voxel_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old_body</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541620506</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7356734.0</td>\n",
       "      <td>9.748614e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           klass  voxel_count  accumulated_voxel_count\n",
       "old_body                                              \n",
       "541620506    6.0    7356734.0             9.748614e+12"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_body_classes_with_size['accumulated_voxel_count'] = \\\n",
    "    np.add.accumulate(neuron_body_classes_with_size['voxel_count'])\n",
    "index_70pct = (neuron_body_classes_with_size['accumulated_voxel_count'] / neuron_body_classes_with_size['voxel_count'].sum() > 0.7).values.nonzero()[0][0]\n",
    "print(index_70pct)\n",
    "neuron_body_classes_with_size[index_70pct:index_70pct+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
